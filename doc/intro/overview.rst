Overview
========

Repository
----------

The root directory of the `git repository <https://github.com/tenpy/tenpy>`_ contains the following folders:

tenpy
    The actual source code of the library.
    Every subfolder contains an ``__init__.py`` file with a summary what the modules in it are good for.
    (This file is also necessary to mark the folder as part of the python package.
    Consequently, other subfolders of the git repo should not include a ``__init__.py`` file.)
toycodes
    Simple toy codes completely independent of the remaining library (i.e., codes in ``tenpy/``).
    These codes should be quite readable and try to give a flavor of how (some of) the algorithms work.
examples
    Some example files demonstrating the usage and interface of the library, including pure python files, jupyter
    notebooks, and example parameter files.
doc
    A folder containing the documentation: the user guide is contained in the ``*.rst`` files.
    The online documentation is autogenerated from these files and the docstrings of the library.
    This folder contains a make file for building the documentation, run ``make help`` for the different options.
    The necessary files for the reference in ``doc/reference`` can be auto-generated/updated with ``make src2html``.
tests
    Contains files with test routines, to be used with `pytest`.
    If you are set up correctly and have `pytest` installed, you can run the test suite with
    ``pytest`` from within the ``tests/`` folder.
build
    This folder is not distributed with the code, but is generated by ``setup.py`` (or ``compile.sh``, respectively).
    It contains compiled versions of the Cython files, and can be ignored (and even removed without loosing functionality).


Layer structure
---------------

There are several layers of abstraction in TeNPy.
While there is a certain hierarchy of how the concepts build up on each other, the user can decide to utilize only some of them.
A maximal flexibility is provided by an object oriented style based on classes, which can be inherited and adjusted to individual demands.

The following figure gives an overview of the most important modules, classes and functions in TeNPy.
Gray backgrounds indicate (sub)modules, yellow backgrounds indicate classes.
Red arrows indicate inheritance relations, dashed black arrows indicate a direct use.
(The individual models might be derived from the :class:`~tenpy.models.model.NearestNeighborModel` depending on the geometry of the lattice.)
There is a fairly clear hierarchy from top-level simulations wrapping everything you want to do in a single job,
over high-level algorithms in the :mod:`tenpy.algorithms` module down to basic
operations from linear algebra in the :mod:`tenpy.linalg` module.

.. image :: /images/overview.*


High-level simulations
----------------------
The high-level interface is given by simulations, which probably handle everything you want to run on a computing cluster job:
Given a set of parameters (often in the form of a parameter input file),
the simulation consists of initializing the model, tensor network and algorithms, running the algorithm,
performing some measurements and finally saving the results to disk.
It also provides some extra functionality like the ability to resume an interrupted simulation,
e.g., if your job got killed on the cluster due to runtime limits.
Ideally, the simulation (sub) class represents the whole simulation from start to end, giving reproducible results
depending only on the parameters given to it.

For example, calling ``tenpy-run parameters.yml`` from the terminal with the following content in the `parameters.yml` file
will run DMRG for a :class:`~tenpy.models.spins.SpinChain`:

.. literalinclude:: /../examples/userguide/i_dmrg_parameters.yml

.. note ::

   The :doc:`/intro/simulations` user guide is a good point to continue reading
   when you finished reading this overview.

To get a sense how things work together, it's instructive to consider the remaining layers in a bottom-to-top order.


Low-level: tensors and linear algebra
-------------------------------------

.. note ::

    See :doc:`/intro/npc` for more information on defining charges for arrays.

The most basic layer is given by in the :mod:`~tenpy.linalg` module, which provides basic features of linear algebra.
In particular, the :mod:`~tenpy.linalg.np_conserved` submodule implements an :class:`~tenpy.linalg.np_conserved.Array` class which is used to represent
the tensors. The basic interface of :mod:`~tenpy.linalg.np_conserved` is very similar to that of the NumPy and SciPy libraries.
However, the :class:`~tenpy.linalg.np_conserved.Array` class implements abelian charge conservation.
If no charges are to be used, one can use 'trivial' arrays, as shown in the following example code.

.. literalinclude:: /../examples/userguide/a_npc_arrays_triv.py


The number and types of symmetries are specified in a :class:`~tenpy.linalg.charges.ChargeInfo` class.
An :class:`~tenpy.linalg.np_conserved.Array` instance represents a tensor satisfying a charge rule specifying which blocks of it are nonzero.
Internally, it stores only the non-zero blocks of the tensor, along with one :class:`~tenpy.linalg.charges.LegCharge` instance for each
leg, which contains the `charges` and sign `qconj` for each leg.
We can combine multiple legs into a single larger :class:`~tenpy.linalg.charges.LegPipe`,
which is derived from the :class:`~tenpy.linalg.charges.LegCharge` and stores all the information necessary to later split the pipe.

The following code explicitly defines the spin-1/2 :math:`S^+, S^-, S^z` operators and
uses them to generate and diagonalize the two-site Hamiltonian :math:`H = \vec{S} \cdot \vec{S}`.
It prints the charge values (by default sorted ascending) and the eigenvalues of H.

.. literalinclude:: /../examples/userguide/b_npc_arrays.py


Sites for the local Hilbert space and tensor networks
-----------------------------------------------------

The next basic concept is that of a local Hilbert space, which is represented by a :class:`~tenpy.networks.site.Site` in TeNPy.
This class does not only label the local states and define the charges, but also
provides onsite operators. For example, the :class:`~tenpy.networks.site.SpinHalfSite` provides the
:math:`S^+, S^-, S^z` operators under the names ``'Sp', 'Sm', 'Sz'``, defined as :class:`~tenpy.linalg.np_conserved.Array` instances similarly as
in the code above.
Since the most common sites like for example the :class:`~tenpy.networks.site.SpinSite` (for general spin S=0.5, 1, 1.5,...), :class:`~tenpy.networks.site.BosonSite` and
:class:`~tenpy.networks.site.FermionSite` are predefined, a user of TeNPy usually does not need to define the local charges and operators explicitly.
The total Hilbert space, i.e, the tensor product of the local Hilbert spaces, is then just given by a
list of :class:`~tenpy.networks.site.Site` instances. If desired, different kinds of :class:`~tenpy.networks.site.Site` can be combined in that list.
This list is then given to classes representing tensor networks like the :class:`~tenpy.networks.mps.MPS` and
:class:`~tenpy.networks.mpo.MPO`.
The tensor network classes also use :class:`~tenpy.linalg.np_conserved.Array` instances for the tensors of the represented network.

The following example illustrates the initialization of a spin-1/2 site, an :class:`~tenpy.networks.mps.MPS` representing the Neel state, and
an :class:`~tenpy.networks.mpo.MPO` representing the Heisenberg model by explicitly defining the `W` tensor.

.. literalinclude:: /../examples/userguide/c_mps_mpo.py

Models
------

.. note ::

    See :doc:`/intro/model` for more information on sites and how to define and extend models on your own.

Technically, the explicit definition of an :class:`~tenpy.networks.mpo.MPO` is already enough to call an algorithm like DMRG in :mod:`~tenpy.algorithms.dmrg`.
However, writing down the `W` tensors is cumbersome especially for more complicated models.
Hence, TeNPy provides another layer of abstraction for the definition of models, which we discuss first.
Different kinds of algorithms require different representations of the Hamiltonian.
Therefore, the library offers to specify the model abstractly by the individual onsite terms and coupling terms of the Hamiltonian.
The following example illustrates this, again for the Heisenberg model.

.. literalinclude:: /../examples/userguide/d_model_1D.py

While this generates the same MPO as in the previous code, this example can easily be adjusted and generalized, for
example to a higher dimensional lattice by just specifying a different lattice.
Internally, the MPO is generated using a finite state machine picture.
This allows not only to translate more complicated Hamiltonians into their corresponding MPOs,
but also to automate the mapping from a higher dimensional lattice to the 1D chain along which the MPS
winds.
Note that this mapping introduces longer-range couplings, so the model can no longer be defined to be a
:class:`~tenpy.models.model.NearestNeighborModel` suited for TEBD if another lattice than the :class:`~tenpy.models.lattice.Chain` is to be used.
Of course, many commonly studied models are also predefined.
For example, the following code initializes the Heisenberg model on a kagome lattice;
the spin liquid nature of the ground state of this model is highly debated in the current literature.

.. literalinclude:: /../examples/userguide/e_model_2D.py

Algorithms
----------

The highest level beyond the wrapping simulations) is given by algorithms like DMRG and TEBD.
They usually need to be initialized with a state, i.e., tensor network like an MPS, and suitable model.
Those are defined in the next lower levels.
The following simple example illustrates the basic structure that the simulation class needs to perform for the same
parameters as the example above, calling the cl:mod:`~tenpy.algorithms.dmrg`.

.. literalinclude:: /../examples/userguide/f_dmrg_finite.py

The switch from DMRG to iDMRG in TeNPy is simply accomplished by a change of the parameter
``"bc_MPS"`` from ``"finite"`` to ``"infinite"``, both for the model and the state.
The returned ``E`` is then the energy density per site.
Due to the translation invariance, one can also evaluate the correlation length, here slightly away from the critical point.

.. literalinclude:: /../examples/userguide/g_dmrg_infinite.py

Running time evolution with TEBD requires an additional loop, during which the desired observables have to be measured.
The following code shows this directly for the infinite version of TEBD.

.. literalinclude:: /../examples/userguide/h_tebd_infinite.py

Note that there is also a simulation class for :class:`~tenpy.simulations.time_evolution.RealTimeEvolution` that can handle this extra loop over time, and
allows to easily switch between different time evolution algorithms.
